{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# import necessary modules\nimport pandas as pd\nimport matplotlib\nimport seaborn as sns\nimport numpy as np\nimport sklearn\nimport matplotlib.pyplot as plt\n# printing the versions\nprint(\"Pandas: \", pd.__version__)\nprint(\"matplotlib: \", matplotlib.__version__)\nprint(\"Scikit-learn: \", sklearn.__version__)\nprint(\"seaborn: \", sns.__version__)\nprint(\"Numpy: \", np.__version__)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7045f841d49190e67416cb13615c4cf4bf8e5689"
      },
      "cell_type": "code",
      "source": "# scikit learn modules for predictions\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "536eee4a9e91c383ed32c0b7f22800bbd4b172a7"
      },
      "cell_type": "code",
      "source": "# loading the data\ngames = pd.read_csv('../input/games.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f1b6dcc9a51543de3738aa1f81237e12387bbc2"
      },
      "cell_type": "code",
      "source": "# exploring the dataset\n# printing the shape of the dataset\nprint(\"The dataset has \", games.shape[0], \" rows and \", games.shape[1], \" columns.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b5076de75fad9cd622560e669775425b6737641c"
      },
      "cell_type": "code",
      "source": "# print out the columns present in the dataset\nprint(\"Features in the dataset: \\n\", list(games.columns))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2acd77320c004028131a32b72393e720025e1112"
      },
      "cell_type": "code",
      "source": "# change the plot style to \"Fivethirtyeight\"\nplt.style.use('fivethirtyeight')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "efbaf81e5f03fae3553f4b0887482f890e428b48"
      },
      "cell_type": "code",
      "source": "# plot the distribution of average_rating\nplt.hist(games[\"average_rating\"])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8d37f9406b1e8e8caa3fb3228fe464df7cefd2c6"
      },
      "cell_type": "markdown",
      "source": "So It's kind of unusual as we can see a large number of ratings falls for '0', so before doing any prediction we need to cross check this."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "784036f350f6d4f0968ce4b32303cf549e90b975"
      },
      "cell_type": "code",
      "source": "# let's get some insight about the data, which means how the data values are there \ndisplay(games.head())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "519b7b0318363e55e00cc9d8a0c09b984503c403"
      },
      "cell_type": "code",
      "source": "# why not we see the data types of each column variable\ndisplay(games.info())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6ad4e10d6deaef3303106c5621b25e06f25ca471"
      },
      "cell_type": "markdown",
      "source": "## Insights:\n\n* In the data we dont have much missing valus.\n* 10 float type, 8 int type and 2 object type"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d52d02e7fea75c4ea9647b0f7b21cc2ab41f00b2"
      },
      "cell_type": "code",
      "source": "# let's see the missing value percentage\ncolumns = games.columns\npercent_missing = games.isnull().sum() * 100 / len(games)\nmissing_value_games = pd.DataFrame({\n    'Column_name': columns,\n    'missing_percent' : percent_missing\n})\ndisplay(missing_value_games)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1e1727c2ea598f9e514116baf711a8adac07cf88"
      },
      "cell_type": "markdown",
      "source": "### Missing values Insight:\n* The missing value table clearly showing that the missing value percentage is very very low. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "78b98409f0dbf3b99b1754cc80b9c86c7bedc65c"
      },
      "cell_type": "code",
      "source": "# print the first row of all the games with zero rating\nprint(games[games[\"average_rating\"] == 0].iloc[0])\n\n# print the first row of all the games with greater than zero rating\nprint(games[games[\"average_rating\"] > 0].iloc[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "428cf36d5a343c2de65df8c3c9c2b94161f22c8e"
      },
      "cell_type": "markdown",
      "source": " ### Insights:\n * If we look into the first row with zero rating it has no user rated that's why it has zero rating\n * whereas in the first row with greater than zero rating has 20113 users rated this. \n * This feature really gives us a great detail about a game, if there is no user rating than it's better to remove that game"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d8834e5ac3e9c369fc6e36e16b6f41af486a53d2"
      },
      "cell_type": "code",
      "source": "# Remove the games with zero users rated\ngames = games[games[\"users_rated\"] > 0]\n\n# As we have very less number of missing values so let's get rid of those rows by dropping them\ngames = games.dropna(axis=0)\n\n# Now let's see the shape after these preprocessings\nprint(\"Shape of the data: \", games.shape[0], \"x\", games.shape[1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b04241905428ef88b579c496361cc8eb622dc2c"
      },
      "cell_type": "code",
      "source": "# Now let's see again the user average rating distribution\nplt.hist(games[\"average_rating\"])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "524e8f3824d92ec0578c5f8877155e3f82d1904d"
      },
      "cell_type": "markdown",
      "source": "### Insights:\nWhoaaa!!! Voilaa!! Look at that '0' rating bar it is just reduced by almost 95% I guess. So this histogram looks much better than the previous one. This looks somehow in normal distribution."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "953e1a8c4ad293be2593f957dd6fd364ea86595c"
      },
      "cell_type": "code",
      "source": "# clean the dataframe\n# drop the id column\ngames = games.drop(\"id\", axis='columns')\ndisplay(games.tail())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8e98895e01a0cfa47abf75368de43ccdf2f0adad"
      },
      "cell_type": "markdown",
      "source": "## correlation analysis"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b5d21f256501958b6ab569c97730e16ac204e95c"
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize = (19, 8))\n# correlation matrix\ngames_corr = games.corr()\n\n# correlation plot\nsns.heatmap(games_corr,\n            xticklabels = games_corr.columns.values,\n            yticklabels = games_corr.columns.values,\n            square = True, annot = False\n)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2cf82f3beed111fc395d977600d86d9fe699761a"
      },
      "cell_type": "markdown",
      "source": "### Insights:\n* The minplaytime and maxplaytime are highly correlated with playingtime\n* minage negatively correlated with users_rated\n* bayes_average_rating also does not say much, It is just the bayes of the rating\n\nSo all n all we need to filtering out the columns and have a good feature set before train the model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "97c6ae5031e0e911b556ed480f0349e5159ce521"
      },
      "cell_type": "code",
      "source": "# list of columns\ncolumns = games.columns.tolist()\n\n# Target variable\ntarget = games[\"average_rating\"]\n\n# filter columns to remove features that are not useful\ncolumns = [c for c in columns if c not in [\"bayes_average_rating\", \"average_rating\", \"type\", \"name\"]]\n\n# built dataframe with filtered columns\ngames = games[columns]\ndisplay(games.columns)\n# display(target)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0181dfef2ea090ef075b64385f5e98ce8186e264"
      },
      "cell_type": "markdown",
      "source": "Now it's time for prepare dataset for training and testing"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a6c64e4024c58fe0ad18e7305bc360e53c303ec9"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\n# split data into train and test\ntrain_games_X, test_games_X, train_games_y, test_games_y = train_test_split(games,target, \n                                                                            test_size=0.25, \n                                                                            random_state=42)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c76a9774a7d88dd9e83ed107d92b7a46276b6e5b"
      },
      "cell_type": "markdown",
      "source": "## Linear Regression\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2413a2eef11ab3d503bec97f3061db3d269037a6"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_squared_error\n\nlin_reg = LinearRegression()\n\n# fit the model\nlin_reg.fit(train_games_X, train_games_y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5b9401e62c8463fe7ae25032b4698ea7cb33a5b5"
      },
      "cell_type": "code",
      "source": "# making predictions for test set\npredictions = lin_reg.predict(test_games_X)\n\n# error between predictions and true values\ndisplay(mean_squared_error(predictions, test_games_y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e5c83c83a2d4e6e9ee3c28038ce382287bbdbf75"
      },
      "cell_type": "markdown",
      "source": "## Random Forest Regressor"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "046cbcd11f4d921839e19ad97ddc0f2c219c3641"
      },
      "cell_type": "code",
      "source": "rf_reg = RandomForestRegressor(n_estimators = 100, min_samples_leaf=10, random_state=42)\n\nrf_reg.fit(train_games_X, train_games_y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d10b8f53b584ee8438c0e92f8de9898b765c8277"
      },
      "cell_type": "code",
      "source": "predictions_rf = rf_reg.predict(test_games_X)\n\n# error calculation\nmean_squared_error(predictions_rf, test_games_y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8211c181e91bd4973f7631c31897090c4819708e"
      },
      "cell_type": "markdown",
      "source": "## Conclusion:\n* So Linear Regression provides a mean_squared error of about 2.08 while random forest regressor a nonlinear regressor provides much better result which is about 1.46.\n* Well this is just directly on test set with out using any cross validation, also not with overfitting so there is a lot of room for improvement.\n* But for now the clear winner here is random forest regressor.\n* We can also test on a single data input (Unseen) to predict the rating."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07fd9162656304293e10956f0f6979e8b008f954"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}